// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v1.181.2
//   protoc               unknown
// source: sedachain/batching/v1/genesis.proto

/* eslint-disable */
import Long from "long";
import _m0 from "protobufjs/minimal";
import { Batch, BatchSignatures, DataResult, DataResultTreeEntries, ValidatorTreeEntry } from "./batching";

/** GenesisState defines the batching module's genesis state. */
export interface GenesisState {
  /**
   * current_batch_number is the batch number of the most recently-
   * created batch.
   */
  currentBatchNumber: bigint;
  batches: Batch[];
  batchData: BatchData[];
  dataResults: GenesisDataResult[];
  batchAssignments: BatchAssignment[];
}

/**
 * BatchAssignment represents a batch assignment for genesis export
 * and import.
 */
export interface BatchAssignment {
  batchNumber: bigint;
  dataRequestId: string;
  dataRequestHeight: bigint;
}

/** BatchData represents a given batch's full data. */
export interface BatchData {
  batchNumber: bigint;
  dataResultEntries: DataResultTreeEntries | undefined;
  validatorEntries: ValidatorTreeEntry[];
  batchSignatures: BatchSignatures[];
}

/** GenesisDataResult includes a data result and its batching status. */
export interface GenesisDataResult {
  batched: boolean;
  dataResult: DataResult | undefined;
}

function createBaseGenesisState(): GenesisState {
  return { currentBatchNumber: 0n, batches: [], batchData: [], dataResults: [], batchAssignments: [] };
}

export const GenesisState = {
  encode(message: GenesisState, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.currentBatchNumber !== 0n) {
      if (BigInt.asUintN(64, message.currentBatchNumber) !== message.currentBatchNumber) {
        throw new globalThis.Error("value provided for field message.currentBatchNumber of type uint64 too large");
      }
      writer.uint32(8).uint64(message.currentBatchNumber.toString());
    }
    for (const v of message.batches) {
      Batch.encode(v!, writer.uint32(18).fork()).ldelim();
    }
    for (const v of message.batchData) {
      BatchData.encode(v!, writer.uint32(26).fork()).ldelim();
    }
    for (const v of message.dataResults) {
      GenesisDataResult.encode(v!, writer.uint32(34).fork()).ldelim();
    }
    for (const v of message.batchAssignments) {
      BatchAssignment.encode(v!, writer.uint32(42).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): GenesisState {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenesisState();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.currentBatchNumber = longToBigint(reader.uint64() as Long);
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.batches.push(Batch.decode(reader, reader.uint32()));
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.batchData.push(BatchData.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.dataResults.push(GenesisDataResult.decode(reader, reader.uint32()));
          continue;
        case 5:
          if (tag !== 42) {
            break;
          }

          message.batchAssignments.push(BatchAssignment.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenesisState {
    return {
      currentBatchNumber: isSet(object.currentBatchNumber) ? BigInt(object.currentBatchNumber) : 0n,
      batches: globalThis.Array.isArray(object?.batches) ? object.batches.map((e: any) => Batch.fromJSON(e)) : [],
      batchData: globalThis.Array.isArray(object?.batchData)
        ? object.batchData.map((e: any) => BatchData.fromJSON(e))
        : [],
      dataResults: globalThis.Array.isArray(object?.dataResults)
        ? object.dataResults.map((e: any) => GenesisDataResult.fromJSON(e))
        : [],
      batchAssignments: globalThis.Array.isArray(object?.batchAssignments)
        ? object.batchAssignments.map((e: any) => BatchAssignment.fromJSON(e))
        : [],
    };
  },

  toJSON(message: GenesisState): unknown {
    const obj: any = {};
    if (message.currentBatchNumber !== 0n) {
      obj.currentBatchNumber = message.currentBatchNumber.toString();
    }
    if (message.batches?.length) {
      obj.batches = message.batches.map((e) => Batch.toJSON(e));
    }
    if (message.batchData?.length) {
      obj.batchData = message.batchData.map((e) => BatchData.toJSON(e));
    }
    if (message.dataResults?.length) {
      obj.dataResults = message.dataResults.map((e) => GenesisDataResult.toJSON(e));
    }
    if (message.batchAssignments?.length) {
      obj.batchAssignments = message.batchAssignments.map((e) => BatchAssignment.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<GenesisState>): GenesisState {
    return GenesisState.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GenesisState>): GenesisState {
    const message = createBaseGenesisState();
    message.currentBatchNumber = object.currentBatchNumber ?? 0n;
    message.batches = object.batches?.map((e) => Batch.fromPartial(e)) || [];
    message.batchData = object.batchData?.map((e) => BatchData.fromPartial(e)) || [];
    message.dataResults = object.dataResults?.map((e) => GenesisDataResult.fromPartial(e)) || [];
    message.batchAssignments = object.batchAssignments?.map((e) => BatchAssignment.fromPartial(e)) || [];
    return message;
  },
};

function createBaseBatchAssignment(): BatchAssignment {
  return { batchNumber: 0n, dataRequestId: "", dataRequestHeight: 0n };
}

export const BatchAssignment = {
  encode(message: BatchAssignment, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.batchNumber !== 0n) {
      if (BigInt.asUintN(64, message.batchNumber) !== message.batchNumber) {
        throw new globalThis.Error("value provided for field message.batchNumber of type uint64 too large");
      }
      writer.uint32(8).uint64(message.batchNumber.toString());
    }
    if (message.dataRequestId !== "") {
      writer.uint32(18).string(message.dataRequestId);
    }
    if (message.dataRequestHeight !== 0n) {
      if (BigInt.asUintN(64, message.dataRequestHeight) !== message.dataRequestHeight) {
        throw new globalThis.Error("value provided for field message.dataRequestHeight of type uint64 too large");
      }
      writer.uint32(24).uint64(message.dataRequestHeight.toString());
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): BatchAssignment {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchAssignment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.batchNumber = longToBigint(reader.uint64() as Long);
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dataRequestId = reader.string();
          continue;
        case 3:
          if (tag !== 24) {
            break;
          }

          message.dataRequestHeight = longToBigint(reader.uint64() as Long);
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchAssignment {
    return {
      batchNumber: isSet(object.batchNumber) ? BigInt(object.batchNumber) : 0n,
      dataRequestId: isSet(object.dataRequestId) ? globalThis.String(object.dataRequestId) : "",
      dataRequestHeight: isSet(object.dataRequestHeight) ? BigInt(object.dataRequestHeight) : 0n,
    };
  },

  toJSON(message: BatchAssignment): unknown {
    const obj: any = {};
    if (message.batchNumber !== 0n) {
      obj.batchNumber = message.batchNumber.toString();
    }
    if (message.dataRequestId !== "") {
      obj.dataRequestId = message.dataRequestId;
    }
    if (message.dataRequestHeight !== 0n) {
      obj.dataRequestHeight = message.dataRequestHeight.toString();
    }
    return obj;
  },

  create(base?: DeepPartial<BatchAssignment>): BatchAssignment {
    return BatchAssignment.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchAssignment>): BatchAssignment {
    const message = createBaseBatchAssignment();
    message.batchNumber = object.batchNumber ?? 0n;
    message.dataRequestId = object.dataRequestId ?? "";
    message.dataRequestHeight = object.dataRequestHeight ?? 0n;
    return message;
  },
};

function createBaseBatchData(): BatchData {
  return { batchNumber: 0n, dataResultEntries: undefined, validatorEntries: [], batchSignatures: [] };
}

export const BatchData = {
  encode(message: BatchData, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.batchNumber !== 0n) {
      if (BigInt.asUintN(64, message.batchNumber) !== message.batchNumber) {
        throw new globalThis.Error("value provided for field message.batchNumber of type uint64 too large");
      }
      writer.uint32(8).uint64(message.batchNumber.toString());
    }
    if (message.dataResultEntries !== undefined) {
      DataResultTreeEntries.encode(message.dataResultEntries, writer.uint32(18).fork()).ldelim();
    }
    for (const v of message.validatorEntries) {
      ValidatorTreeEntry.encode(v!, writer.uint32(26).fork()).ldelim();
    }
    for (const v of message.batchSignatures) {
      BatchSignatures.encode(v!, writer.uint32(34).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): BatchData {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBatchData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.batchNumber = longToBigint(reader.uint64() as Long);
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dataResultEntries = DataResultTreeEntries.decode(reader, reader.uint32());
          continue;
        case 3:
          if (tag !== 26) {
            break;
          }

          message.validatorEntries.push(ValidatorTreeEntry.decode(reader, reader.uint32()));
          continue;
        case 4:
          if (tag !== 34) {
            break;
          }

          message.batchSignatures.push(BatchSignatures.decode(reader, reader.uint32()));
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BatchData {
    return {
      batchNumber: isSet(object.batchNumber) ? BigInt(object.batchNumber) : 0n,
      dataResultEntries: isSet(object.dataResultEntries)
        ? DataResultTreeEntries.fromJSON(object.dataResultEntries)
        : undefined,
      validatorEntries: globalThis.Array.isArray(object?.validatorEntries)
        ? object.validatorEntries.map((e: any) => ValidatorTreeEntry.fromJSON(e))
        : [],
      batchSignatures: globalThis.Array.isArray(object?.batchSignatures)
        ? object.batchSignatures.map((e: any) => BatchSignatures.fromJSON(e))
        : [],
    };
  },

  toJSON(message: BatchData): unknown {
    const obj: any = {};
    if (message.batchNumber !== 0n) {
      obj.batchNumber = message.batchNumber.toString();
    }
    if (message.dataResultEntries !== undefined) {
      obj.dataResultEntries = DataResultTreeEntries.toJSON(message.dataResultEntries);
    }
    if (message.validatorEntries?.length) {
      obj.validatorEntries = message.validatorEntries.map((e) => ValidatorTreeEntry.toJSON(e));
    }
    if (message.batchSignatures?.length) {
      obj.batchSignatures = message.batchSignatures.map((e) => BatchSignatures.toJSON(e));
    }
    return obj;
  },

  create(base?: DeepPartial<BatchData>): BatchData {
    return BatchData.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<BatchData>): BatchData {
    const message = createBaseBatchData();
    message.batchNumber = object.batchNumber ?? 0n;
    message.dataResultEntries = (object.dataResultEntries !== undefined && object.dataResultEntries !== null)
      ? DataResultTreeEntries.fromPartial(object.dataResultEntries)
      : undefined;
    message.validatorEntries = object.validatorEntries?.map((e) => ValidatorTreeEntry.fromPartial(e)) || [];
    message.batchSignatures = object.batchSignatures?.map((e) => BatchSignatures.fromPartial(e)) || [];
    return message;
  },
};

function createBaseGenesisDataResult(): GenesisDataResult {
  return { batched: false, dataResult: undefined };
}

export const GenesisDataResult = {
  encode(message: GenesisDataResult, writer: _m0.Writer = _m0.Writer.create()): _m0.Writer {
    if (message.batched !== false) {
      writer.uint32(8).bool(message.batched);
    }
    if (message.dataResult !== undefined) {
      DataResult.encode(message.dataResult, writer.uint32(18).fork()).ldelim();
    }
    return writer;
  },

  decode(input: _m0.Reader | Uint8Array, length?: number): GenesisDataResult {
    const reader = input instanceof _m0.Reader ? input : _m0.Reader.create(input);
    let end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGenesisDataResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1:
          if (tag !== 8) {
            break;
          }

          message.batched = reader.bool();
          continue;
        case 2:
          if (tag !== 18) {
            break;
          }

          message.dataResult = DataResult.decode(reader, reader.uint32());
          continue;
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skipType(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GenesisDataResult {
    return {
      batched: isSet(object.batched) ? globalThis.Boolean(object.batched) : false,
      dataResult: isSet(object.dataResult) ? DataResult.fromJSON(object.dataResult) : undefined,
    };
  },

  toJSON(message: GenesisDataResult): unknown {
    const obj: any = {};
    if (message.batched !== false) {
      obj.batched = message.batched;
    }
    if (message.dataResult !== undefined) {
      obj.dataResult = DataResult.toJSON(message.dataResult);
    }
    return obj;
  },

  create(base?: DeepPartial<GenesisDataResult>): GenesisDataResult {
    return GenesisDataResult.fromPartial(base ?? {});
  },
  fromPartial(object: DeepPartial<GenesisDataResult>): GenesisDataResult {
    const message = createBaseGenesisDataResult();
    message.batched = object.batched ?? false;
    message.dataResult = (object.dataResult !== undefined && object.dataResult !== null)
      ? DataResult.fromPartial(object.dataResult)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | bigint | undefined;

type DeepPartial<T> = T extends Builtin ? T
  : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

function longToBigint(long: Long) {
  return BigInt(long.toString());
}

if (_m0.util.Long !== Long) {
  _m0.util.Long = Long as any;
  _m0.configure();
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}
